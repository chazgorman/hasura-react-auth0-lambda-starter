ENV:=${USER}-development
# ROOT_DIR:=$(shell dirname $(realpath $(lastword $(MAKEFILE_LIST))))
# DOTENV := .env

REACT_DIR:=../frontend-react
LAMBDA_DIR:=../backend-lambdas

# ECR_REPO_URL_BASE := 840787491930.dkr.ecr.us-west-2.amazonaws.com
# ECR_AP_BASE_REPO_NAME := ap_karada_base
# ECR_AP_BASE_REPO_URL := ${ECR_REPO_URL_BASE}/${ECR_AP_BASE_REPO_NAME}

# ECR_REPO_NAME := ap_aws_test
# ECR_REPO_URL := ${ECR_REPO_URL_BASE}/${ECR_REPO_NAME}


.ONESHELL:
SHELL=/bin/bash 
.EXPORT_ALL_VARIABLES:

include .env.${ENV}

test_env: 
	echo "Using environment ${ENV}"

install:
	brew install gettext ;\
	brew link --force gettext  ;\
	yarn && cd - && \
	cd ${REACT_DIR} && yarn && cd - && \
	cd ${LAMBDA_DIR} && yarn && cd -


start_react:
	export PORT=${REACT_APP_PORT} ;\
	cd ${REACT_DIR} && yarn start

# due to recursive variable defs, you may have to run this 3 times (outside of make)
# to fully expand all variables
generate_dotenv_files:
	echo '### DO NOT EDIT THIS FILE DIRECTLY.  EDIT the base file in common' > .env.${ENV} ; \
	cat .env.${ENV}.base | envsubst >> .env.${ENV} ;     \
	echo '### DO NOT EDIT THIS FILE DIRECTLY.  EDIT BASE in common' > ${REACT_DIR}/.env ; \
	grep REACT_APP .env.${ENV}  >> ${REACT_DIR}/.env
	# cat "<!-- DO NOT EDIT THIS FILE!!!  -->" | envsubst > "../frontend-ios/env.plist"; \
	# cat "../frontend-ios/env.tpl.plist" | envsubst >> "../frontend-ios/env.plist"; \

ngrok: 
	export NGROK=.ngrok-generated.yml ;  envsubst < ngrok-base.yml > ${NGROK} ; \
	ngrok start -config ${NGROK} --all 

ngrok_silent:
	export NGROK=.ngrok-generated.yml ;  envsubst < ngrok-base.yml > ${NGROK} ; \
	ngrok start -config ${NGROK} --all > /dev/null 

# TERRAFORM
TF_DIR:=../backend-terraform
tf_all: tf_setup tf_init tf_apply
tf_authzero_all: tf_setup tf_authzero_init tf_authzero_apply

tf_test: 
	cd ${TF_DIR} ; \
	./run-terraform.sh  apply

tf_setup:
	cd ${TF_DIR} ; \
	./init-tf-bucket.sh

tf_init:
	cd ${TF_DIR} ; \
	./run-terraform.sh init

tf_authzero_init:
	cd ${TF_DIR} ; \
	./run-terraform-authzero.sh init

tf_apply:
	cd ${TF_DIR} ; \
	./run-terraform.sh apply

tf_authzero_apply:
	cd ${TF_DIR} ; \
	./run-terraform-authzero.sh apply

react_start:
	cd ${REACT_DIR} ; yarn run start


sls_info: 
	cd ${LAMBDA_DIR} && \
	NODE_ENV=${ENV} sls info -s ${ENV}

sls_remove: 
	cd ${LAMBDA_DIR} && \
	read -p "Are you sure you want to destroy sls in  ${ENV} [y/n]? " -n 1 -r; \
	if [[ $$REPLY =~ ^[Yy] ]]; \
	then \
		printf "\nyes going ahead\n"; \
		NODE_ENV=${ENV} sls remove -s ${ENV} ;\
	else \
		printf "\n skipping\n"  ;\
	fi

sls_local: 
	cd ${LAMBDA_DIR} && \
	node --max-old-space-size=4096 node_modules/serverless/bin/serverless offline --useSeparateProcesses --useChildProcesses start 

sls_deploy_aws:
	cd ${LAMBDA_DIR} && \
	cp ../common/.env.${ENV} ./ && \
	export HASURA_GRAPHQL_JWT_KEY_RAW=$(curl "https://${REACT_APP_AUTH0_DOMAIN}/pem") && \
	NODE_ENV=${ENV} sls deploy  -s ${ENV} --aws-s3-accelerate --force && \
	rm .env.${ENV} && \


gql_gen_all: gql_gen_react gql_gen_sls

gql_gen_react: gql_gen_react_schema 
	cd ${REACT_DIR} ;                                  \
	gql-gen --config gql-codegen.yml ;\
	cd -

gql_gen_react_schema: hasura_metadata_reload
	cd ${REACT_DIR} ;                                  \
	mkdir -p ./src/__generated__/;                     \
	gq ${REACT_APP_HASURA_ENDPOINT}  -H "X-Hasura-Admin-Secret: ${HASURA_GRAPHQL_ADMIN_SECRET}" --introspect --format json > ./src/__generated__/schema.json  ;\
	cd -

gql_gen_sls: gql_gen_sls_schema
	cd ../backend-lambdas; \
	gql-gen --config gql-codegen.yml \
	cd -;

gql_gen_sls_schema: 
	cd ../backend-lambdas; \
	mkdir -p ./src/__generated__/; \
	gq ${REACT_APP_HASURA_ENDPOINT} -H "X-Hasura-Admin-Secret: ${HASURA_GRAPHQL_ADMIN_SECRET}" --introspect --format json > ./src/__generated__/schema.json;  \
	gq ${LAMBDA_ENDPOINT} --introspect --format json > ./src/__generated__/lambda_schema.json ; \
	cd -

hasura_up:
	export HASURA_GRAPHQL_JWT_KEY_RAW=$$(curl -L "http://${REACT_APP_AUTH0_DOMAIN}/pem" );\
	cd ../backend-hasura; \
	docker-compose kill; \
	docker-compose up --build

hasura_up_delay:
	for i in `seq 1 300` ; \
	do \
		curl -f -s ${LAMBDA_ENDPOINT} && sleep 5 && make hasura_up && exit 0 ; \
		echo . ;\
		sleep 5 ;\
	done ;\
	echo Failed waiting for sls lambdas && exit 1

hasura_metadata_reload:
	cd ../backend-hasura; \
	REMOTE_ENDPOINT=https://$${SUBDOMAIN_HASURA}.$${ROOT_DOMAIN} ; \
	API_ENDPOINT=$${REMOTE_ENDPOINT}/v1/query  ; \
	echo "MD UPDATE on $${REMOTE_ENDPOINT} and reload to $${API_ENDPOINT} "; \
	curl -f -H "x-hasura-admin-secret: ${HASURA_GRAPHQL_ADMIN_SECRET}" \
	    -X POST \
	    -d "{\"type\": \"reload_remote_schema\", \"args\": {\"name\": \"LAMBDA_ENDPOINT\"}}"  "$${API_ENDPOINT}" && \
	echo "Remote schema successful" \
	hasura metadata reload --skip-update-check --admin-secret ${HASURA_GRAPHQL_ADMIN_SECRET} --endpoint $${REMOTE_ENDPOINT}

hasura_migrate_apply:
	cd ../backend-hasura; \
	hasura migrate apply --skip-update-check --admin-secret ${HASURA_GRAPHQL_ADMIN_SECRET} --endpoint http://localhost:${HASURA_EXPOSED_PORT} 

hasura_hard_reset:
	# export $(grep -v '^#' ../sc-common/.env.production | sed -e 's/\\n/__NEWLINE__/g' | sed -e 's/=__NEWLINE__-----END CERTIFICATE-----__NEWLINE__/__END_CERT__/' | sed -e 's/ /__SPACE__/g' | xargs) ; 
	read -p "Are you sure you want to migrate to $${REMOTE_ENDPOINT} [y/n]? " -n 1 -r; \
	if [[ $$REPLY =~ ^[Yy] ]]; \
	then \
		printf "\nyes going ahead\n"; \
		cd ../backend-hasura; \
		docker-compose down --rmi all --volumes; \
	else \
		printf "\n skipping\n"  ;\
	fi

hasura_migrate_apply_remote:
	# export $(grep -v '^#' ../sc-common/.env.production | sed -e 's/\\n/__NEWLINE__/g' | sed -e 's/=__NEWLINE__-----END CERTIFICATE-----__NEWLINE__/__END_CERT__/' | sed -e 's/ /__SPACE__/g' | xargs) ; 
	export PROD_HASURA_SECRET=$$(grep HASURA_GRAPHQL_ADMIN_SECRET ../sc-common/.env.production | sed -e 's/.*\=//' ) ;\
	echo "Admin secret: '$${PROD_HASURA_SECRET}' . " ;\
	REMOTE_ENDPOINT=https://hasura.{$ENV}.$${HASURA_TF_AWS_DOMAIN} ; \
	read -p "Are you sure you want to migrate to $${REMOTE_ENDPOINT} [y/n]? " -n 1 -r; \
	if [[ $$REPLY =~ ^[Yy] ]]; \
	then \
		printf "\nyes going ahead\n"; \
		cd ../backend-hasura; \
		hasura migrate apply --skip-update-check --admin-secret $${PROD_HASURA_SECRET} --endpoint $${REMOTE_ENDPOINT} ;\
	else \
		printf "\n skipping\n"  ;\
	fi

hasura_console_delay: 
	for i in `seq 1 300` ; \
	do \
		curl -f -s http://localhost:${HASURA_EXPOSED_PORT} && make hasura_console && exit 0 ;\
		echo  . ;\
		sleep 5 ;\
	done; \
	echo Failed waiting for rails && exit 1

hasura_console: 
	cd ../backend-hasura; \
	hasura console --admin-secret ${HASURA_GRAPHQL_ADMIN_SECRET} --skip-update-check --no-browser --console-port ${HASURA_CONSOLE_PORT} --endpoint http://localhost:${HASURA_EXPOSED_PORT}

hasura_migrate_squash:
	cd ../backend-hasura && \
	cp -rf migrations/*MANUAL_SQL_MIGRATION* manual-migrations/ && \
	git mv migrations `date +%F`-migrations && \
	mkdir -p migrations && \
	hasura migrate create "init" --from-server --skip-update-check --admin-secret ${HASURA_GRAPHQL_ADMIN_SECRET} --endpoint http://localhost:${HASURA_EXPOSED_PORT}  && \
	mv migrations/*_init migrations/0000000000001_init && \
	cp -r manual-migrations/* migrations/ && \
	echo "Remember the CITEXT extension, enum stuff, and cancellation policies"


###### OLD COMMANDS: 

hasura_migrate_prod:
	echo 'UNIMPLEMENTED'


hack_fix_react_scripts:
	sed -i "" "s/protocol: 'ws',/protocol: window.location.protocol === 'https:' ? 'wss' : 'ws',/g" node_modules/react-dev-utils/webpackHotDevClient.js


copy_envs:
	echo "#### DO NOT EDIT THIS FILE, edit ${DOTENV} ####" > .env ; \
	grep '^REACT_APP' ${DOTENV} >> .env

prep_app: hack_fix_react_scripts copy_envs

# 
# # https://askubuntu.com/questions/682869/how-do-i-install-a-different-python-version-using-apt-get
# # Need to force python 3.5
# ap_docker_base_build: ap_models
# 	echo "--- Building Base Docker Image"
# 	export $$(grep -v '^#' ${DOTENV} | xargs)  && \
# 	cd ../../AlphaPose && \
# 	aws --profile $${AWS_CLI_PROFILE} ecr list-images \
# 		--repository-name ${ECR_AP_BASE_REPO_NAME} --region us-west-2 | \
# 		grep $${AP_BASE_IMAGE_DOCKER_VERSION} || \
# 	docker build -t ${ECR_AP_BASE_REPO_URL}:$${AP_BASE_IMAGE_DOCKER_VERSION}  .
# 
# ap_docker_build: ap_docker_base_build
# 	echo "--- Building Docker Image"
# 	export $$(grep -v '^#' ${DOTENV} | xargs)  && \
# 	cd ../../AlphaPose/karada-additions && \
# 	echo "version = \"$${AP_DOCKER_VERSION}\"" >> version.py && \
# 	aws --profile $${AWS_CLI_PROFILE} ecr list-images \
# 		--repository-name ${ECR_REPO_NAME} --region us-west-2 | \
# 		grep $${AP_DOCKER_VERSION} || \
# 	docker build -t ${ECR_REPO_URL}:$${AP_DOCKER_VERSION}  \
# 		--build-arg BASE_TAG=$${AP_BASE_IMAGE_DOCKER_VERSION}  .
# 
# ap_docker_base_push: ap_docker_base_build
# 	echo "--- Pushing Base Docker Image"
# 	export $$(grep -v '^#' ${DOTENV} | xargs)  && \
# 	cd ../../AlphaPose && \
# 	aws --profile $${AWS_CLI_PROFILE} ecr list-images \
# 		--repository-name ${ECR_AP_BASE_REPO_NAME} --region us-west-2 | \
# 		grep $${AP_BASE_IMAGE_DOCKER_VERSION} || \
# 	($$(aws ecr get-login --no-include-email --region us-west-2 --profile $${AWS_CLI_PROFILE}) && \
# 	docker push ${ECR_AP_BASE_REPO_URL}:$${AP_BASE_IMAGE_DOCKER_VERSION} )
# 
# ap_docker_push: ap_docker_build ap_docker_base_push
# 	echo "--- Pushing Docker Image"
# 	export $$(grep -v '^#' ${DOTENV} | xargs)  && \
# 	cd ../../AlphaPose/karada-additions && \
# 	aws --profile $${AWS_CLI_PROFILE} ecr list-images \
# 		--repository-name ${ECR_REPO_NAME} --region us-west-2 | \
# 		grep $${AP_DOCKER_VERSION} || \
# 	($$(aws ecr get-login --no-include-email --region us-west-2 --profile $${AWS_CLI_PROFILE}) && \
# 	docker push ${ECR_REPO_URL}:$${AP_DOCKER_VERSION} )
# 
# test_ap_docker_image: ap_docker_build
# 	export $$(grep -v '^#' ${DOTENV} | xargs)  && \
# 	docker run \
# 		-e AWS_ACCESS_KEY_ID=$${AWS_ACCESS_KEY_ID} \
# 		-e AWS_SECRET_ACCESS_KEY=$${AWS_SECRET_ACCESS_KEY} \
# 		-e karada_s3_bucket=karada-static-test-files-non-terraform \
# 		-e karada_output_prefix=output/00000000-0000-0000-0000-000000000000 \
# 		-e karada_s3_key=dropbox/00000000-0000-0000-0000-000000000000/test.mp4 \
# 		${ECR_REPO_URL}:$${AP_DOCKER_VERSION} 
# 
# terraform: ap_docker_push
# 	cd backend-terraform && ./deploy.sh
# 	cd backend-terraform && ./run-terraform.sh apply -auto-approve
# 